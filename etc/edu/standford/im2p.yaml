name: A Hierarchical Approach for Generating Descriptive Image Paragraphs
website: https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html
tags:
  - image
  - caption
  - paragraphs

papers:
  technical description: 
    url: https://arxiv.org/pdf/1611.06607.pdf
    bibtex: |
      @inproceedings{krause2016paragraphs,
        title={A Hierarchical Approach for Generating Descriptive Image Paragraphs},
        author={Krause, Jonathan and Johnson, Justin and Krishna, Ranjay and Fei-Fei,
        Li}, booktitle={Computer Vision and Patterm Recognition (CVPR)}, year={2017}
      }

description: |
   Recent progress on image captioning has made it possible to generate novel
   sentences describing images in natural language, but compressing an image
   into a single sentence can describe visual content in only coarse detail.
   While one new captioning approach, dense captioning, can potentially describe
   images in finer levels of detail by captioning many regions within an image,
   it in turn is unable to produce a coherent story for an image. In this paper
   we overcome these limitations by generating entire paragraphs for describing
   images, which can tell detailed, unified stories. We develop a model that
   decomposes both images and paragraphs into their constituent parts, detecting
   semantic regions in images and using a hierarchical recurrent neural network
   to reason about language. Linguistic analysis confirms the complexity of the
   paragraph generation task, and thorough experiments on a new dataset of image
   and paragraph pairs demonstrate the effectiveness of our approach.

    With this paper, we are releasing a new dataset to allow researchers to
    benchmark their progress in generating paragraphs that tell a story about an
    image. The dataset contains 19,561 images from the Visual Genome dataset.
    Each image contains one paragraph. The training/val/test sets contains
    14,575/2487/2489 images. We show in our paper that the paragraphs are more
    diverse than their corresponding sentences descriptions with more verbs,
    co-references and adjectives.

    Since all the images are also part of the Visual Genome dataset, Each image also
    contains 50 region descriptions (short phrases describing parts of an image), 35
    objects, 26 attributes and 21 relationships and 17 question-answer pairs.

    ![https://cs.stanford.edu/people/ranjaykrishna/im2p/examples.png]

download: 
  handler: /multiple/Simple
  list:
    paragraphs:
      handler: /single/File
      url: http://visualgenome.org/static/data/dataset/paragraphs_v1.json.zip
    train:
      handler: /single/File
      url: https://cs.stanford.edu/people/ranjaykrishna/im2p/train_split.json
    val:
      handler: /single/File
      url: https://cs.stanford.edu/people/ranjaykrishna/im2p/val_split.json
    data:
      handler: /single/File
      url: https://cs.stanford.edu/people/ranjaykrishna/im2p/test_split.json